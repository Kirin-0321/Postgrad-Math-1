# 大数定律与中心极限定理

## 依概率收敛与依分布收敛

### 依概率收敛的定义

随机变量序列$\{X_n\}$**依概率收敛**(converge in probability)于随机变量$X$，如果对任意的$\varepsilon > 0$，有：
$$\lim_{n \to \infty} P(|X_n - X| \geq \varepsilon) = 0$$

或等价地：
$$\lim_{n \to \infty} P(|X_n - X| < \varepsilon) = 1$$

记作$X_n \stackrel{P}{\longrightarrow} X$或$\operatorname{plim}_{n \to \infty} X_n = X$。

特别地，若随机变量序列$\{X_n\}$依概率收敛于常数$c$，则称$\{X_n\}$是依概率收敛的，常数$c$是$\{X_n\}$的**概率极限**。

### 依分布收敛的定义

随机变量序列$\{X_n\}$**依分布收敛**(converge in distribution)于随机变量$X$，如果它们的分布函数序列$\{F_n(x)\}$在$X$的分布函数$F(x)$的每个连续点$x$处都满足：
$$\lim_{n \to \infty} F_n(x) = F(x)$$

记作$X_n \stackrel{D}{\longrightarrow} X$或$X_n \Rightarrow X$。

### 两种收敛的关系

1. 依概率收敛推导出依分布收敛，即若$X_n \stackrel{P}{\longrightarrow} X$，则$X_n \stackrel{D}{\longrightarrow} X$
2. 反之不成立，即依分布收敛不能推导出依概率收敛
3. 若$X_n \stackrel{D}{\longrightarrow} c$（$c$为常数），则$X_n \stackrel{P}{\longrightarrow} c$
4. 若$X_n \stackrel{P}{\longrightarrow} X$，$g$为连续函数，则$g(X_n) \stackrel{P}{\longrightarrow} g(X)$
5. 若$X_n \stackrel{D}{\longrightarrow} X$，$g$为连续函数，则$g(X_n) \stackrel{D}{\longrightarrow} g(X)$

## 大数定律

大数定律(Law of Large Numbers)是概率论中描述大量重复实验的平均结果趋近于期望值的定理，是概率论的基本定律之一。

### 切比雪夫大数定律

设随机变量序列$X_1, X_2, \cdots, X_n, \cdots$相互独立，且具有相同的数学期望$E(X_i) = \mu$和有限的方差$Var(X_i) \leq \sigma^2 < \infty$，则对任意$\varepsilon > 0$，有：
$$\lim_{n \to \infty} P\left(\left|\frac{1}{n}\sum_{i=1}^{n}X_i - \mu\right| \geq \varepsilon\right) = 0$$

这表明随机变量序列的算术平均值$\frac{1}{n}\sum_{i=1}^{n}X_i$依概率收敛于它们的共同期望$\mu$，即：
$$\frac{1}{n}\sum_{i=1}^{n}X_i \stackrel{P}{\longrightarrow} \mu$$

切比雪夫大数定律对独立但不同分布的随机变量序列也成立，只要它们具有有限的方差。

### 伯努利大数定律

设$f_A$是$n$次独立重复试验中事件$A$发生的频数，$p$是事件$A$在每次试验中发生的概率，则对任意$\varepsilon > 0$，有：
$$\lim_{n \to \infty} P\left(\left|\frac{f_A}{n} - p\right| \geq \varepsilon\right) = 0$$

这表明当试验次数$n$足够大时，事件$A$发生的频率$\frac{f_A}{n}$接近于其概率$p$：
$$\frac{f_A}{n} \stackrel{P}{\longrightarrow} p$$

伯努利大数定律是切比雪夫大数定律的特例，其中$X_i$是示性随机变量，表示第$i$次试验中事件$A$是否发生。

### 辛钦大数定律

设随机变量序列$X_1, X_2, \cdots, X_n, \cdots$相互独立同分布，且具有数学期望$E(X_i) = \mu$，则对任意$\varepsilon > 0$，有：
$$\lim_{n \to \infty} P\left(\left|\frac{1}{n}\sum_{i=1}^{n}X_i - \mu\right| \geq \varepsilon\right) = 0$$

这表明随机变量序列的算术平均值$\frac{1}{n}\sum_{i=1}^{n}X_i$依概率收敛于它们的共同期望$\mu$：
$$\frac{1}{n}\sum_{i=1}^{n}X_i \stackrel{P}{\longrightarrow} \mu$$

辛钦大数定律与切比雪夫大数定律的区别在于辛钦大数定律不要求随机变量有有限方差，但要求随机变量同分布。

### 大数定律的应用

大数定律在统计学、保险学、物理学等领域有广泛应用：

1. **统计推断**：频率统计方法的理论基础
2. **蒙特卡洛方法**：通过大量随机抽样来近似计算期望值
3. **精算学**：保险公司基于大数定律确定保费和准备金
4. **赌博和博弈**：长期来看，赌场的优势会体现（赌徒谬误）
5. **热力学**：解释宏观物理量稳定性的统计力学基础

## 中心极限定理

中心极限定理(Central Limit Theorem, CLT)是概率论中最重要的定理之一，阐述了大量相互独立的随机变量之和的分布趋近于正态分布的性质。

### 独立同分布的中心极限定理

设随机变量序列$X_1, X_2, \cdots, X_n, \cdots$相互独立同分布，且具有数学期望$E(X_i) = \mu$和有限的方差$Var(X_i) = \sigma^2 > 0$，则随机变量和的标准化形式：
$$Z_n = \frac{\sum_{i=1}^{n}X_i - n\mu}{\sigma\sqrt{n}} = \frac{\overline{X}_n - \mu}{\sigma/\sqrt{n}}$$

的分布函数$F_n(x)$对任意$x$满足：
$$\lim_{n \to \infty} F_n(x) = \Phi(x)$$

其中$\Phi(x)$是标准正态分布$N(0,1)$的分布函数。

这表明随机变量和的标准化形式$Z_n$依分布收敛于标准正态分布：
$$Z_n \stackrel{D}{\longrightarrow} N(0,1)$$

或等价地，随机变量和$\sum_{i=1}^{n}X_i$近似服从正态分布$N(n\mu, n\sigma^2)$，算术平均值$\overline{X}_n$近似服从正态分布$N(\mu, \sigma^2/n)$。

### 林德伯格-列维中心极限定理

设随机变量序列$X_1, X_2, \cdots, X_n, \cdots$相互独立，具有数学期望$E(X_i) = \mu_i$和有限的方差$Var(X_i) = \sigma_i^2 > 0$，令$B_n^2 = \sum_{i=1}^{n}\sigma_i^2$，若对任意$\varepsilon > 0$，有：
$$\lim_{n \to \infty} \frac{1}{B_n^2} \sum_{i=1}^{n} E[(X_i - \mu_i)^2 \cdot I(|X_i - \mu_i| \geq \varepsilon B_n)] = 0$$

其中$I$是示性函数，则随机变量和的标准化形式：
$$Z_n = \frac{\sum_{i=1}^{n}X_i - \sum_{i=1}^{n}\mu_i}{B_n}$$

的分布函数$F_n(x)$对任意$x$满足：
$$\lim_{n \to \infty} F_n(x) = \Phi(x)$$

即$Z_n \stackrel{D}{\longrightarrow} N(0,1)$。

林德伯格-列维中心极限定理是更一般的中心极限定理，它适用于独立但不同分布的随机变量序列。

### 棣莫弗-拉普拉斯中心极限定理

设随机变量$\eta_n$服从参数为$n$和$p$的二项分布$B(n,p)$，则对任意实数$x$，有：
$$\lim_{n \to \infty} P\left(\frac{\eta_n - np}{\sqrt{np(1-p)}} \leq x\right) = \Phi(x)$$

这表明二项分布$B(n,p)$可以用正态分布$N(np, np(1-p))$近似，即：
$$\eta_n \approx N(np, np(1-p))$$

当$n$足够大时，上述近似是比较精确的。

### 二项分布的正态近似

当$n$较大时，二项分布$B(n,p)$可以用正态分布$N(np, np(1-p))$近似，即：
$$P(\eta_n = k) \approx \frac{1}{\sqrt{2\pi np(1-p)}} \exp\left(-\frac{(k-np)^2}{2np(1-p)}\right)$$

通常使用连续性校正，即：
$$P(\eta_n = k) \approx P\left(k-0.5 < X < k+0.5\right)$$

其中$X \sim N(np, np(1-p))$。

对于区间概率，有：
$$P(a \leq \eta_n \leq b) \approx P\left(a-0.5 < X < b+0.5\right)$$

在实际应用中，当$np \geq 5$且$n(1-p) \geq 5$时，正态近似通常是比较准确的。

## 正态总体的抽样分布定理

### χ²分布的性质与应用

若$X_1, X_2, \cdots, X_n$是来自正态分布$N(0, 1)$的独立同分布的随机变量，则统计量：
$$\chi^2 = \sum_{i=1}^{n} X_i^2$$

服从自由度为$n$的$\chi^2$分布，记为$\chi^2 \sim \chi^2(n)$。

$\chi^2$分布的主要性质：
1. 若$X \sim N(\mu, \sigma^2)$，则$\frac{(n-1)S^2}{\sigma^2} \sim \chi^2(n-1)$，其中$S^2$是样本方差
2. 若$X_1 \sim \chi^2(n_1)$和$X_2 \sim \chi^2(n_2)$，且$X_1$与$X_2$相互独立，则$X_1 + X_2 \sim \chi^2(n_1 + n_2)$
3. $E(\chi^2(n)) = n$，$Var(\chi^2(n)) = 2n$
4. 当$n$很大时，$\chi^2(n)$近似服从正态分布$N(n, 2n)$

$\chi^2$分布在假设检验、拟合优度检验、独立性检验等方面有广泛应用。

### t分布的性质与应用

若$X \sim N(0, 1)$，$Y \sim \chi^2(n)$，且$X$与$Y$相互独立，则统计量：
$$T = \frac{X}{\sqrt{Y/n}}$$

服从自由度为$n$的$t$分布，记为$T \sim t(n)$。

$t$分布的主要性质：
1. $t$分布的密度函数关于原点对称，即$f_T(-t) = f_T(t)$
2. 当$n = 1$时，$t$分布是柯西分布；当$n \to \infty$时，$t$分布趋近于标准正态分布
3. 若$X_1, X_2, \cdots, X_n$是来自正态分布$N(\mu, \sigma^2)$的样本，则统计量：
   $$T = \frac{\overline{X} - \mu}{S/\sqrt{n}} \sim t(n-1)$$
   其中$\overline{X}$是样本均值，$S$是样本标准差
4. $E(T) = 0$（当$n > 1$时），$Var(T) = \frac{n}{n-2}$（当$n > 2$时）

$t$分布在小样本情况下的均值检验、区间估计中有重要应用。

### F分布的性质与应用

若$U \sim \chi^2(n_1)$，$V \sim \chi^2(n_2)$，且$U$与$V$相互独立，则统计量：
$$F = \frac{U/n_1}{V/n_2}$$

服从自由度为$(n_1, n_2)$的$F$分布，记为$F \sim F(n_1, n_2)$。

$F$分布的主要性质：
1. 若$F \sim F(n_1, n_2)$，则$\frac{1}{F} \sim F(n_2, n_1)$
2. 若$T \sim t(n)$，则$T^2 \sim F(1, n)$
3. 若$X_1, X_2, \cdots, X_{n_1}$和$Y_1, Y_2, \cdots, Y_{n_2}$分别是来自正态分布$N(\mu_1, \sigma_1^2)$和$N(\mu_2, \sigma_2^2)$的两个独立样本，则当$\sigma_1^2 = \sigma_2^2$时，统计量：
   $$F = \frac{S_1^2}{S_2^2} \sim F(n_1-1, n_2-1)$$
   其中$S_1^2$和$S_2^2$分别是两个样本的样本方差
4. $E(F) = \frac{n_2}{n_2-2}$（当$n_2 > 2$时）
   
$F$分布在方差分析、方差比检验等方面有重要应用。 